{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfsim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 18>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow_datasets\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtfds\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# try:\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m#     import tensorflow_similarity as tfsim\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# except ModuleNotFoundError:\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m#     !pip install tensorflow_similarity\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m#     import tensorflow_similarity as tfsim\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m \u001B[43mtfsim\u001B[49m\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mtf_cap_memory()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tfsim' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "try:\n",
    "    import tensorflow_similarity as tfsim\n",
    "except ModuleNotFoundError:\n",
    "    !pip install tensorflow_similarity\n",
    "    import tensorflow_similarity as tfsim\n",
    "\n",
    "tfsim.utils.tf_cap_memory()  # Avoid GPU memory blow up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "IMG_SIZE = 300  # slightly larger than EfficienNetB0 size to allow random crops.\n",
    "TARGET_IMG_SIZE = 224\n",
    "\n",
    "def resize(img, label, shape=(IMG_SIZE, IMG_SIZE)):\n",
    "    \"\"\"Resize images to required shape.\"\"\"\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        img = tf.cast(img, dtype=\"int32\")\n",
    "        img = tf.image.resize_with_pad(img, *shape)\n",
    "        return img, label\n",
    "\n",
    "def img_augmentation(img_batch, y, *args):\n",
    "    \"\"\"Randomize image shape and orientation\"\"\"\n",
    "    img_batch = tf.keras.layers.RandomCrop(TARGET_IMG_SIZE, TARGET_IMG_SIZE)(img_batch)\n",
    "    img_batch = tf.image.random_flip_left_right(img_batch)\n",
    "    return img_batch, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Dataset**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar100\n"
     ]
    }
   ],
   "source": [
    "MIN_NO_CLASSES = 20  #@param {type:\"integer\"}\n",
    "EXAMPLES_PER_CLASS_PER_BATCH = 4  #@param {type:\"slider\", min:1, max:20, step:1}\n",
    "\n",
    "num_of_classes = tfds.image_classification.Cifar100()._info().features['label'].num_classes\n",
    "ds_name = tfds.image_classification.Cifar100.name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_classes = int(num_of_classes * 0.6)\n",
    "train_cls = random.sample(range(num_of_classes), k=training_classes)\n",
    "test_cls = [cls_id for cls_id in range(num_of_classes) if cls_id not in train_cls]\n",
    "\n",
    "print(f\"Class IDs seen during training {train_cls}\")\n",
    "\n",
    "# use the train split for training\n",
    "train_ds = tfsim.samplers.TFDatasetMultiShotMemorySampler(\n",
    "    ds_name,\n",
    "    splits=\"train\",\n",
    "    examples_per_class_per_batch=EXAMPLES_PER_CLASS_PER_BATCH,\n",
    "    classes_per_batch=training_classes,\n",
    "    preprocess_fn=resize,\n",
    "    class_list=train_cls,\n",
    "    augmenter=img_augmentation,\n",
    ")\n",
    "\n",
    "# use the test split for indexing and querying\n",
    "test_ds = tfsim.samplers.TFDatasetMultiShotMemorySampler(\n",
    "    ds_name,\n",
    "    splits=\"test\",\n",
    "    total_examples_per_class=20,\n",
    "    classes_per_batch=training_classes,\n",
    "    class_list=test_cls,\n",
    "    preprocess_fn=resize,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_TARGETS = 200  #@param {type:\"integer\"}\n",
    "NUM_QUERIES = 300  #@param {type:\"integer\"}\n",
    "k = 3  #@param {type:\"integer\"}\n",
    "log_dir = \"logs/%d/\" % (time())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup EvalCallback by splitting the test data into targets and queries.\n",
    "queries_x, queries_y = test_ds.get_slice(0, NUM_QUERIES)\n",
    "targets_x, targets_y = test_ds.get_slice(NUM_QUERIES, NUM_TARGETS)\n",
    "tsc = tfsim.callbacks.EvalCallback(\n",
    "    queries_x,\n",
    "    queries_y,\n",
    "    targets_x,\n",
    "    targets_y,\n",
    "    metrics=[\"f1\"],\n",
    "    k=k,\n",
    "    # tb_logdir=log_dir  # uncomment if you want to track in tensorboard\n",
    ")\n",
    "\n",
    "# Setup an EvalCallback for a known and unknown class split.\n",
    "val_loss = tfsim.callbacks.EvalCallback(\n",
    "    queries_x,\n",
    "    queries_y,\n",
    "    targets_x,\n",
    "    targets_y,\n",
    "    metrics=[\"binary_accuracy\"],\n",
    "    known_classes=tf.constant(train_cls),\n",
    "    k=k,\n",
    "    # tb_logdir=log_dir  # uncomment if you want to track in tensorboard\n",
    ")\n",
    "\n",
    "# Adding the Tensorboard callback to track metrics in tensorboard.\n",
    "# tbc = tf.keras.callbacks.TensorBoard(log_dir=log_dir) # uncomment if you want to track in tensorboard\n",
    "\n",
    "callbacks = [\n",
    "    val_loss,\n",
    "    tsc,\n",
    "    # tbc # uncomment if you want to track in tensorboard\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model**\n",
    "Hyper-parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 128  #@param {type:\"slider\", min:32, max:1024, step:32}\n",
    "epochs = 5  #@param {type:\"slider\", min:1, max:64, step:1}\n",
    "LR = 0.0001\n",
    "steps_per_epoch = 100  #@param {type:\"integer\"}\n",
    "val_steps = 50  #@param {type:\"integer\"}\n",
    "positive_mining_strategy='hard'  #@param ['hard', 'easy']\n",
    "negative_mining_strategy='semi-hard'  #@param ['hard', 'semi-hard', 'easy']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tfsim.architectures.EfficientNetSim(\n",
    "    train_ds.example_shape,\n",
    "    EMBEDDING_SIZE,\n",
    "    pooling=\"gem\",    # Can change to use `gem` -> GeneralizedMeanPooling2D\n",
    "    gem_p=3.0,        # Increase the contrast between activations in the feature map.\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss = tfsim.losses.TripletLoss(distance='cosine',\n",
    "                                positive_mining_strategy=positive_mining_strategy,\n",
    "                                negative_mining_strategy=negative_mining_strategy)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(LR), loss=loss)\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_ds,\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=callbacks,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend([\"loss\", \"val_loss\"])\n",
    "plt.title(f\"Loss: {loss.name} - LR: {LR}\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"binary_accuracy_known_classes\"])\n",
    "plt.plot(history.history[\"binary_accuracy_unknown_classes\"])\n",
    "plt.legend([\"binary_accuracy_known\", \"binary_accuracy_unknown\"])\n",
    "plt.title(f\"Known | Unknown binary_accuracy: {loss.name} - LR: {LR}\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# What is indexed\n",
    "index_size = 360\n",
    "query_size = 360\n",
    "index_x, index_y = test_ds.get_slice(0, index_size)\n",
    "index_data = tf.cast(index_x, dtype=\"int32\")\n",
    "\n",
    "# what will be used as never seen before queries to test performance\n",
    "test_x, test_y = test_ds.get_slice(index_size, query_size)\n",
    "test_y = [int(c) for c in test_y]\n",
    "test_data = tf.cast(test_x, dtype=\"int32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.reset_index()\n",
    "model.index(index_x, index_y, data=index_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_examples = 5  #@param {type:\"slider\", min:1, max:20, step:1}\n",
    "num_neigboors = 5  #@param {type:\"slider\", min:1, max:20, step:1}\n",
    "idxs = random.sample(range(len(test_y)), num_examples)\n",
    "batch = tf.gather(test_x, idxs)\n",
    "nns = model.lookup(batch, k=num_neigboors)\n",
    "for bid, nn in zip(idxs, nns):\n",
    "    # view results close by\n",
    "    if test_y[bid] in train_cls:\n",
    "        display(Markdown(\"**Known Class**\"))\n",
    "    else:\n",
    "        display(Markdown(\"**Unknown Class**\"))\n",
    "    tfsim.visualization.viz_neigbors_imgs(test_data[bid], test_y[bid], nn, cmap='Grays')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_examples_to_clusters = 720  # @param {type:\"integer\"}\n",
    "thumb_size = 96  # @param {type:\"integer\"}\n",
    "plot_size = 800\n",
    "vx, vy = test_ds.get_slice(0, num_examples_to_clusters)\n",
    "tfsim.visualization.projector(\n",
    "    model.predict(vx), labels=vy, images=vx, image_size=thumb_size, plot_size=plot_size\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_calibration_samples = 1000  # @param {type:\"integer\"}\n",
    "calibration = model.calibrate(\n",
    "    x_train[:num_calibration_samples],\n",
    "    y_train[:num_calibration_samples],\n",
    "    extra_metrics=[\"precision\", \"recall\", \"binary_accuracy\"],\n",
    "    verbose=1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}